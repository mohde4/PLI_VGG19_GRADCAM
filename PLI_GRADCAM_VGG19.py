import numpy as npimport tensorflow as tffrom tensorflow.keras.applications import VGG19from tensorflow.keras.preprocessing.image import ImageDataGeneratorfrom tensorflow.keras.models import Modelfrom tensorflow.keras.layers import Dense, Flattenfrom tensorflow.keras.optimizers import Adamimport matplotlib.pyplot as pltimport cv2# Load the datadef load_data():    # Assuming datasets are organized in directories for pneumonia and normal cases    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)        train_data = datagen.flow_from_directory(        'path_to_dataset',  # Provide dataset directory path        target_size=(224, 224),        batch_size=32,        class_mode='binary',        subset='training'    )        val_data = datagen.flow_from_directory(        'path_to_dataset',        target_size=(224, 224),        batch_size=32,        class_mode='binary',        subset='validation'    )        return train_data, val_data# Build and compile the VGG19 modeldef build_model():    base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))    x = base_model.output    x = Flatten()(x)    x = Dense(128, activation='relu')(x)    predictions = Dense(1, activation='sigmoid')(x)        model = Model(inputs=base_model.input, outputs=predictions)        for layer in base_model.layers:        layer.trainable = False        model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])    return model# Train the modeldef train_model(model, train_data, val_data):    model.fit(train_data, validation_data=val_data, epochs=10, batch_size=32)    return model# Grad-CAM Implementationdef grad_cam(model, img_array, layer_name='block5_conv4'):    grad_model = Model(        [model.inputs], [model.get_layer(layer_name).output, model.output]    )        with tf.GradientTape() as tape:        conv_outputs, predictions = grad_model(img_array)        loss = predictions[:, 0]        grads = tape.gradient(loss, conv_outputs)[0]    guided_grads = grads * (grads > 0)    conv_outputs = conv_outputs[0]    weights = tf.reduce_mean(guided_grads, axis=(0, 1))    grad_cam = tf.reduce_sum(tf.multiply(weights, conv_outputs), axis=-1)        heatmap = np.maximum(grad_cam, 0) / np.max(grad_cam)    return heatmap# PLI Implementation (simplified heatmap)def pli_heatmap(img_array, model):    with tf.GradientTape() as tape:        preds = model(img_array)        loss = preds[:, 0]        grads = tape.gradient(loss, img_array)[0]    grads = (grads - np.min(grads)) / (np.max(grads) - np.min(grads) + 1e-8)    pli_heatmap = np.mean(grads, axis=-1).squeeze()    return pli_heatmap# Display Heatmapdef display_heatmap(heatmap, original_img_path):    img = cv2.imread(original_img_path)    img = cv2.resize(img, (224, 224))    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))    heatmap = np.uint8(255 * heatmap)    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)        overlay = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)    plt.imshow(overlay)    plt.axis('off')    plt.show()# Main executiontrain_data, val_data = load_data()model = build_model()trained_model = train_model(model, train_data, val_data)# Load a query imageimg_path = 'path_to_query_image.jpg'img_array = np.expand_dims(cv2.resize(cv2.imread(img_path), (224, 224)), axis=0) / 255.0# Generate Grad-CAM and PLI heatmapsgradcam_heatmap = grad_cam(trained_model, img_array)pli_heatmap_result = pli_heatmap(img_array, trained_model)# Display the heatmapsdisplay_heatmap(gradcam_heatmap, img_path)display_heatmap(pli_heatmap_result, img_path)